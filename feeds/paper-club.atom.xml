<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>RAndom NoTes - Paper Club</title><link href="http://blog.bshi.engineer/" rel="alternate"></link><link href="http://blog.bshi.engineer/feeds/paper-club.atom.xml" rel="self"></link><id>http://blog.bshi.engineer/</id><updated>2017-09-21T10:24:00-04:00</updated><entry><title>Paper Club -- StarSpace</title><link href="http://blog.bshi.engineer/weekly-paper-club-001-network-embedding.html" rel="alternate"></link><published>2017-09-21T00:00:00-04:00</published><updated>2017-09-21T10:24:00-04:00</updated><author><name>Dash Shi</name></author><id>tag:blog.bshi.engineer,2017-09-21:/weekly-paper-club-001-network-embedding.html</id><summary type="html">&lt;p&gt;StarSpace is a general representation learning model that learn entity embeddings using feature embeddings.&lt;/p&gt;</summary><content type="html">&lt;h2&gt;StarSpace&lt;/h2&gt;
&lt;p&gt;This is a new paper submitted to AAAI'18 by Facebook AI Research (FAIR) and the full article can be found on &lt;a href="https://arxiv.org/abs/1709.03856"&gt;Arxiv&lt;/a&gt;, the code is available at &lt;a href="https://github.com/facebookresearch/Starspace"&gt;GitHub&lt;/a&gt;. One of the author &lt;a href="https://research.fb.com/people/bordes-antoine/"&gt;Antoine Bordes&lt;/a&gt; is also the author of TransE, a well-known Knowledge Graph Completion model.&lt;/p&gt;
&lt;p&gt;In general, StarSpace is capable of learning embeddings from a set of finite features. If we have a finite feature dictionary &lt;span class="math"&gt;\(\mathcal{D}\)&lt;/span&gt; and has a feature matrix &lt;span class="math"&gt;\(F \in \mathbb{R}^{\mathcal{D}\times d}\)&lt;/span&gt;, in which &lt;span class="math"&gt;\(F_i\)&lt;/span&gt; is the &lt;span class="math"&gt;\(d\)&lt;/span&gt;-dimensional embedding of &lt;span class="math"&gt;\(i^{\mathsf{th}}\)&lt;/span&gt; feature. Then for an entity &lt;span class="math"&gt;\(a\)&lt;/span&gt; with k features &lt;span class="math"&gt;\(\mathbf{a}=\{i_1,\cdots,i_k\}\)&lt;/span&gt;, the embedding of entity &lt;span class="math"&gt;\(a\)&lt;/span&gt; is defined as unweighted sum of all these feature embeddings &lt;span class="math"&gt;\(\sum_{i\in\mathbf{a}}F_i\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;When training the model, StarSpace uses &lt;/p&gt;
&lt;div class="math"&gt;$$\sum_{(a,b)\in E^+, b^- \in E^-} L^{\textsf{batch}}(sim(a,b),sim(a,b^-_1),\ldots,sim(a,b^-_k))$$&lt;/div&gt;
&lt;p&gt;in which&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class="math"&gt;\(E^+\)&lt;/span&gt; is the positive entity pair set.&lt;/li&gt;
&lt;li&gt;&lt;span class="math"&gt;\(E^-\)&lt;/span&gt; is the negative pair set that &lt;span class="math"&gt;\(\{(a,b) | (a,\cdot) \in E^+, (a,b) \notin E^+ \}\)&lt;/span&gt;, which means &lt;span class="math"&gt;\(a\)&lt;/span&gt; and &lt;span class="math"&gt;\(b\)&lt;/span&gt; has the correct left-hand and right-hand entity type but &lt;span class="math"&gt;\(b\)&lt;/span&gt; is not the correct right-hand element. For example if we are predicting LocatedIn, then &lt;span class="math"&gt;\(a\)&lt;/span&gt; will be a building and &lt;span class="math"&gt;\(b\)&lt;/span&gt; will be a location.&lt;/li&gt;
&lt;li&gt;The sim function, according to the authors, is best to be inner product for smaller number of features (&lt;span class="math"&gt;\(|\mathbf{a}|\)&lt;/span&gt;) and cosine for larger number of features.&lt;/li&gt;
&lt;li&gt;&lt;span class="math"&gt;\(\mathcal{L}\)&lt;/span&gt; is better to be ranking loss instead of softmax loss. (What is the ranking loss in this case? It should not be the standard pairwise ranking loss I guess)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;It is relatively easy to do the multi-class classification because the labels can be viewed as &lt;span class="math"&gt;\(b\)&lt;/span&gt;, same thing applies to word/sentence/document similarity in which each pair of similar word/sentence/document can be represented by &lt;span class="math"&gt;\(a\)&lt;/span&gt; and &lt;span class="math"&gt;\(b\)&lt;/span&gt;. As for Knowledge Graph Completion, &lt;span class="math"&gt;\(a\)&lt;/span&gt; could be h &amp;amp; r and &lt;span class="math"&gt;\(b\)&lt;/span&gt; be t or &lt;span class="math"&gt;\(a\)&lt;/span&gt; be h and &lt;span class="math"&gt;\(b\)&lt;/span&gt; be r &amp;amp; t.&lt;/p&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</content><category term="research"></category><category term="deep learning"></category><category term="paper club"></category></entry></feed>